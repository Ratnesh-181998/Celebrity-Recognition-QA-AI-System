#HLD & LLD
ğŸ”¹ High-Level Design (HLD)
1ï¸âƒ£ System Overview
The system allows users to upload an image of a celebrity and ask natural language questions.
It uses computer vision and a multimodal LLM to detect the celebrity and generate contextual answers.
The application is cloud-deployed, containerized, and CI/CD enabled.
________________________________________
2ï¸âƒ£ High-Level Architecture
User
 â†“
Frontend (HTML / CSS)
 â†“
Backend API (Flask)
 â†“
AI Inference Layer
 â”œâ”€â”€ Image Processing (OpenCV)
 â”œâ”€â”€ Celebrity Detection (Vision Transformer)
 â””â”€â”€ Q/A Engine (Groq LLM)
 â†“
Response to User
________________________________________
3ï¸âƒ£ Major Components
A. Frontend
â€¢	Image upload
â€¢	Question input
â€¢	Displays AI response
B. Backend (Flask API)
â€¢	Request handling
â€¢	Routing
â€¢	Orchestration of ML pipeline
C. AI Layer
â€¢	Image preprocessing
â€¢	Celebrity detection
â€¢	Question answering
D. Deployment & Infrastructure
â€¢	Docker for containerization
â€¢	CircleCI for CI/CD
â€¢	GCP Artifact Registry for image storage
â€¢	GKE for application deployment
________________________________________
4ï¸âƒ£ High-Level Deployment Flow
Developer â†’ GitHub â†’ CircleCI â†’ Docker
        â†’ GCP Artifact Registry â†’ GKE â†’ Users
________________________________________
5ï¸âƒ£ HLD Key Design Decisions
â€¢	Stateless backend for scalability
â€¢	Microservice-ready architecture
â€¢	Managed Kubernetes (GKE) for reliability
â€¢	LLM offloaded to Groq for low latency
________________________________________
ğŸ”¹ Low-Level Design (LLD)
1ï¸âƒ£ Backend API Design
Endpoint
POST /analyze
Request Payload
{
  "image": "uploaded_image.jpg",
  "question": "Who is this person?"
}
Response Payload
{
  "celebrity": "Name",
  "answer": "AI generated response"
}
________________________________________
2ï¸âƒ£ Flask Application Structure
app/
â”œâ”€â”€ app.py              # Flask entry point
â”œâ”€â”€ routes.py           # API routes
â”œâ”€â”€ image_handler.py    # Image upload & validation
â”œâ”€â”€ preprocessing.py    # OpenCV image processing
â”œâ”€â”€ detector.py         # Vision Transformer logic
â”œâ”€â”€ qa_engine.py        # Groq LLM integration
â”œâ”€â”€ utils.py            # Helper functions
â””â”€â”€ requirements.txt
________________________________________
3ï¸âƒ£ Image Processing Flow (LLD)
1.	Receive image from request
2.	Validate file type & size
3.	Resize image
4.	Normalize pixel values
5.	Convert to model-ready format
Library: OpenCV (Python)
________________________________________
4ï¸âƒ£ Celebrity Detection Flow (LLD)
1.	Input processed image
2.	Generate image embeddings
3.	Compare embeddings with known celebrity representations
4.	Select highest similarity match
5.	Return celebrity identity
Model: Vision Transformer
________________________________________
5ï¸âƒ£ Q/A Engine Flow (LLD)
1.	Combine:
o	Detected celebrity name
o	User question
2.	Create structured prompt
3.	Send prompt to Groq LLM
4.	Receive AI-generated answer
5.	Return response to backend
________________________________________
6ï¸âƒ£ Docker & Kubernetes (LLD)
Docker
â€¢	Flask + ML dependencies packaged in one image
â€¢	Single Dockerfile
Kubernetes
â€¢	Deployment:
o	Multiple replicas
â€¢	Service:
o	Exposes Flask API
â€¢	Optional:
o	Auto-scaling
________________________________________
7ï¸âƒ£ CI/CD Pipeline (LLD)
1. Code push to GitHub
2. CircleCI triggers pipeline
3. Docker image build
4. Push image to GCP Artifact Registry
5. Deploy updated image to GKE
________________________________________
8ï¸âƒ£ Error Handling (LLD)
â€¢	Invalid image format â†’ 400 error
â€¢	No celebrity detected â†’ fallback response
â€¢	LLM timeout â†’ retry / graceful error
________________________________________
9ï¸âƒ£ Performance & Scalability (LLD)
â€¢	Stateless Flask APIs
â€¢	Horizontal scaling via Kubernetes
â€¢	Separate inference logic
â€¢	Ready for async processing in future
________________________________________
ğŸ”¹ 1-Line HLD + LLD I Summary
â€œAt a high level, this is a cloud-native AI system where a Flask API orchestrates image preprocessing, celebrity detection using Vision Transformers, and multimodal Q&A using Groq LLM, deployed on GKE with Docker and CI/CD via CircleCI.â€
